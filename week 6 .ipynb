{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5a4fa34",
   "metadata": {},
   "source": [
    "classification metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "469fea9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87cfce44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c , h , f are classess corresponding to the 9 players \n",
    "y_actual  = [\"c\" , \"h\", \"f\", \"c\",\"h\" , \"f\" , \"c\" ,  \"h\" , \"h\"] # actual classes corresponding \n",
    "# 9 players \n",
    "y_pred =   [\"c\" , \"c\", \"f\", \"h\",\"h\"  ,\"c\" , \"c\" , \"f\" , \"f\"] # predicted class for each player "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47f4f70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 1 0]\n",
      " [1 1 2]\n",
      " [1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(y_actual , y_pred, labels= [\"c\" , \"h\", \"f\"]) # ordering of \n",
    "#y_pred and y_actual is important in the arguement of funciton\n",
    "print(cm) # confusion matrix for a multiclass classification problem\n",
    "# interpretation of the confusion matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c1d47ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the rows represent actual values and the columns represent predicted values .as unlike binary classification\n",
    "# we don't only have positve and negative classes but we have multiple classes.\n",
    "# so the first row is for the class cricket and the second & third rows are for hockey and football class resp."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5faf6f8",
   "metadata": {},
   "source": [
    "the first row says that :\n",
    "we have 2 + 1 +0   = 3  samples for the cricket class , 2:TC(True cricket) 1:FH(false hockey) 0:Ff(false football) & so on for other rows...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03002075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           c       0.50      0.67      0.57         3\n",
      "           h       0.50      0.25      0.33         4\n",
      "           f       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.44         9\n",
      "   macro avg       0.44      0.47      0.43         9\n",
      "weighted avg       0.46      0.44      0.43         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_actual ,y_pred , labels = [\"c\" , \"h\" , \"f\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b45577",
   "metadata": {},
   "source": [
    "- precision for class cricket  = TC / (TC +  FC(belonging to hockey)   +  FC(belonging to football) )\n",
    "- recall for class cricket  = TC / TC + FH(belong to class cricket) + Ff(belongint to class cricket)\n",
    "- precision cricket = 2  /  (2  + 1 +  1 ) = 2 / 4 = 0.5\n",
    "- recall for cricket = 2 /  ( 2 + 1 + 0 ) = 2 /3  = 0.67\n",
    "\n",
    "- Precision for hockey  class = TH / TH +  FH(belonging to cricket)  +   FH(belonging to football)\n",
    "- recall for hockey class  = TH / (TH  + FC(belonging to hockey) +   Ff(belonging to hockey))\n",
    "- precisoin hockey  = 1 / ( 1 + 1 + 0)  = 0.5 \n",
    "- recall   hockey = 1 / ( 1 + 1 + 2) =  0.25\n",
    "\n",
    "-  macro avg :is the arithmatic mean of metrics so, (0.50 + 0.50 + 0.33) /3 = 0.44 <-- precision macro avg\n",
    "-  support is the no.of samples from each classess.\n",
    "-  weighted average : weighted avg of metrics so ,(3\\*0.50  + 4\\*0.50  + 2\\*0.33) / (3 + 4 + 2) = 0.46 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
